\chapter[Metodologia]{Metodologia}
Neste capítulo é apresentado como foi realizada a implementação do algoritmo de treinamento do classificador LDA em um sistema coprocessado hardware-software, detalhando todos os módulos que compõem a implementação.

\section{Algoritmo Implementado}
Em 2010 o francês Fabien Lotte publicou um trabalho com objetivo de comparar as implementações de algoritmos de extração de características de sinais provenientes de atividades cerebrais, além de propor um novo algoritmo para extração de características dos sinais \cite{F.Lotte}.\\
Para coleta de resultados de seu trabalho, Lotte utilizou o algoritmo de classificação LDA e a base de dados \textit{BCI Competition III - Dataset IVa}, obtendo como melhor resultado o extrator de características CSP, conforme apresentado anteriormente na Tabela \ref{arte_state}.\\
O algoritmo foi desenvolvido utilizando a plataforma \textit{Matlab}, onde foram utilizados os recursos e funções da plataforma. A Figura \ref{processos_alg} apresenta um diagrama de atividades que descreve as funções utilizadas no algoritmo.

\begin{figure}[h]
	\centering
	\includegraphics[keepaspectratio=true,scale=0.6]{figuras/Processos_Algoritmo_Lotte.PNG}
	\caption{Atividades realizadas pelo algoritmo de \cite{F.Lotte}.}
	\label{processos_alg}
\end{figure}

Utilizando-se dos dados de treinamento do \textit{BCI Competition III - Data Set -IVa}, o algoritmo inicia-se realizando a filtragem dos sinais a partir de um filtro \textit{Butterworth} passa faixas de {$5^a$} ordem, mantendo os sinais das faixas {$\alpha$} e {$\beta$} e atenuando as demais frequências. Em seguida, é realizado o processo de extração de características utilizando o algoritmo CSP. Logo após, é realizado o processo de treinamento, onde são calculados hiperplanos que melhor separam as classes. Por fim, para o processo de testes o algoritmo utiliza dos hiperplanos gerados pela função de treinamento para classificar os sinais de testes, também fornecidos pelo \textit{BCI Competition III - Data Set -IVa}. Pro fim, são disponibilizados os resultados de acurácia e tempo de treinamento.

\section{Implementação em Sistema Coprocessado}

Conforme apresentado, o objetivo deste trabalho é o estudo dos ganhos ou perdas no processamento do algoritmo de treinamento do classificador LDA, implementado em um coprocessamento hardware-software, utilizando-se do SoC \textit{Zynq} embarcado no kit de desenvolvimento \textit{Xilinx Zybo Board} modelo 70-10, comparado com a implementação realizada por \cite{F.Lotte} e a implementação em software executado sobre um SO Linux embarcado nos processadores ARM, também disponíveis no SoC. \\
Sendo assim, o trabalho se restringiu à implementação em sistema coprocessado as atividades que compõem a função de treinamento do classificador LDA (atividades destacadas) da Figura \ref{processos_alg}.\\
A Figura \ref{processos_train} apresenta um diagrama de atividades que descreve a função de treinamento do classificador LDA.

\begin{figure}[h]
	\centering
	\includegraphics[keepaspectratio=true,scale=0.6]{figuras/Processos_LDA_Train.PNG}
	\caption{Atividades realizadas pelo algoritmo de treinamento do classificador LDA, desenvolvido por \cite{F.Lotte}.}
	\label{processos_train}
\end{figure}

Inicialmente é realizada a separação dos sinais em dois conjuntos de dados que representam os dados referentes às duas classes em estudo. Em seguida são calculadas as médias dos sinais de cada classe. Estes valores são repassados para a função de cálculo da matriz de covariância (ou dispersão), onde são realizados cálculos matriciais conforme apresentado na Equação \ref{eq: dispersaosb}. Posteriormente são calculados os hiperplanos a partir da covariância das características dos sinais. Estes hiperplanos representam os parâmetros de treinamento do classificador. São a partir deles que os sinais de teste são classificados.\\

Na realização do coprocessamento as funções de cálculo de média e cálculo de covariancia são as duas funções que apresentam um maior esforço computacional. Portanto ambas as funções foram mapeadas em hardware, utilizando-se da linguagem VHDL, a fim de acelerar o algoritmo de treinamento explorando o paralelismo de processos em hardware \textit{FPGA Artix-7} disponível no SoC, enquanto as demais funções foram compiladas em software na linguagem C, executada através de um SO Linux embarcado nos processadores \textit{ARM Cortex-A9}.

\subsection{Ferramentas utilizadas}
Para estudo das implementações (\textit{Matlab}, software e coprocessamento) utilizamos cinco ferramentas principais:\\
\begin{itemize}
	\item Software\textit{Matlab R2016a - \textit{Student License}} - Utilizado para reproduzir os resultados obtidos por \cite{F.Lotte};
	\item SO Linux - Utilizado como ambiente de desenvolvimento de software embarcado;
	\item Software \textit{Vivado - v.2017.4} - Utilizado para desenvolver, integrar e sintetizar os IP's de cálculo em ponto flutuante das funções média e covariância;
	\item \textit{SDK - v.2017.4} - Utilizado para desenvolver o arquivo fsbl.elf e para compilar o arquivo BOOT.bin.
\end{itemize}

Para implementação em software e implementação coprocessada utilizamos o SoC \textit{Zynq} embarcado no kit de desenvolvimento \textit{Zybo Board}

\subsection{Metodologias de desenvolvimento}
\subsubsection{Implementação em Hardware}
Para implementação das funções de cálculo de média e cálculo da matriz de covarinância em FPGA foi adotada a metodologia \textit{bottom-up}, na qual cada sub-bloco desenvolvido foi testado antes de ser inserido ao bloco principal, bloco de integração de todos sub-blocos do projeto, também conhecido como \textit{Top module}.
Os cálculos foram realizados através dos blocos de propriedade intelectual (IP) desenvolvidos por \cite{munoz2010tradeoff}. Os IPs realiazam cálculos matemáticos em unidades de ponto flutuante de acordo com o padrão IEEE-754 com registradores de 27 bits, representados com:
\begin{itemize}
	\item expoente: 8 bits;
	\item mantiza: 18 bits;
	\item sinal: 1 bit.
\end{itemize}
Foram criados componentes para paralelizar o processo dos cálculos, buscando o maior nível de paralelismo.
Para a função média foram implementados um total de 20(vinte) componentes em paralelo. Já para a função de covariância foram implementados 4 componentes em paralelo, conforme apresentado nas Figuras \ref{somador} e \ref{covariancia}.

\begin{figure}[h]
	\centering
	\includegraphics[keepaspectratio=true,scale=0.55]{figuras/rtl_media.png}
	\caption{Bloco para cálculo de média com vinte somas em paralelo.}
	\label{somador}
\end{figure}
\newpage
\begin{figure}[h]
	\centering
	\includegraphics[keepaspectratio=true,scale=0.35]{figuras/rtl_covariancia.png}
	\caption{Bloco para cálculo da matriz de covariancia com quatro cálculos em paralelo.}
	\label{covariancia}
\end{figure}

A técnica utilizada na implementação do projeto foi a \textit{pipelining} que se baseia na divisão de uma tarefa em subtarefas sequenciais de forma simultânea, onde cada novo cálculo só é realizado após o fim do cálculo anterior. 

Todos os módulos desenvolvidos foram atribuidos à um novo IP com barramento AXI4-Lite
para realizar a comunicação com o procesador ARM. O diagrama de comunicação entre o IP e o processador é apresentado no Anexo 01 deste de trabalho.

Os processos realizados para implementação são apresentados na Figura \ref{diagram_hardware}.

\begin{figure}[h]
  \centering
  \includegraphics[keepaspectratio=true,scale=1.0]{figuras/fluxograma_hardware.PNG}
  \caption{Fluxograma de implementação de hardware em um SoC. Adaptado de \cite{zynqBook}}
  \label{diagram_hardware}
\end{figure}

\subsection{Análise estatística}
Para efeito de análise comparatória foram coletados as seguintes informações pós síntese e implementação:

\begin{itemize}[noitemsep]
	\item Consumo de hardware: LUTs, FFs, blocos de DSP, blocos de memória RAM, I/O;
	\item Dados de desempenho: frequência de operação e tempo de execução;
	\item Estimação do consumo de energético.
	\item Estimação estatística do erro quadrático de implementação.
\end{itemize}

\section{Implementação em software}

\subsection{Métodos e Técnicas}
Para o auxílio desta implementação, foi instalado o sistema operacional \textit{Debian Linux} sobre os cores ARM, cujo os recursos e passos necessários
para a instalação do SO estão contidos no Anexo 02.

O processo para implementação seguiu o método \textit{bottom-up}, blocos de códigos menores foram implementados e testados separadamente, com a finalidade de todos os blocos serem integrados e testados em um único bloco principal. Todas as codificações foram implementadas utilizando a linguagem de programação C, para compilar o código principal usamos o compilador GCC \textit{(GNU Compiler Collection)}. Com esse método conseguimos realizar uma análise de perfil das funções implementadas onde foram reportados os tempo de execução de cada uma das funções, sendo assim possível deduzir as funções que necessitam de maior esforço computacional. As entradas para programa desenvolvido são os sinais de treinamento fornecidos pelo \textit{dataset IVa} do \textit{BCI Competition III}.

Como parâmetro de análise estatística foram coletados os seguintes dados:

\begin{itemize}[noitemsep]
\item Consumo de memória
\item Tempo de execução
\item Erro da implementação em comparação aos resultados obtidos por \cite{F.Lotte}
\end{itemize}

\subsection{Integração}
Toda a integração do projeto coprocessado é possibilitado pelo uso do barramento AXI4-Lite, que interliga a PL com a PS, 
um esquemático do processo de escrita e leitura nos IP através do barramento AXI4-Lite pode ser observado na Figura \ref{axi_bus}
\newpage

\begin{figure}[h]
	\centering
	\includegraphics[keepaspectratio=true,scale=0.5]{figuras/axi_bus.png}
	\caption{Fluxo de dados para leitura e escrita no barramento AXI Fone: \cite{user-guide-axi}}
	\label{axi_bus}
\end{figure}

Para escrita e leitura de dados nos IPs através da aplicação implementada em software, ultilizamos a função mmap() que faz parte da biblioteca <sys/mman.h>, esta função cria um novo mapeamento de memória no endereço de memória virtual no seu processo de chamada. Esse novo endereço começa no endereço de memória do IP (com AXI), com isso é possivel ler e escrever no endereço memória de de qualquer IP, desde que a memória esteja devidamente mapeada. 

\section{\textit{Data Set IVa}}

Em ambas as implementações serão utilizadas o \textit{Data Set IVa} da \textit{BCI Competition III} \cite{BCICompetition}, para efeito de testes e validações do sistema.
Os dados \textit{Data Set IVa} foram adquiridos e armazenados utilizando amplificadores do tipo \textit{BrainAmp} e uma capa de eletrodos de 128 canais. Foram utilizados 118 canais de EEG posicionados de acordo com o sistema 10-20. Cada um destes canais foram filtrados em banda passante, utilizando um filtro \textit{butterworth} de quinta ordem entre as frequências de 0,05 e 200 Hz, posteriormente foram digitalizados com uma frequência de amostragem de 1 kHz com precisão de 16 bits, apresentando uma resolução de 0,1 $\mu$V, além disso também foram disponibilizados os mesmos dados com uma frequência de amostragem de 100 Hz \cite{siteBCI}.
\vspace{\onelineskip}

